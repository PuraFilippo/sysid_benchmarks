{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df653a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataset_numba import WHDataset, CSTRDataset_numba\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer_sim import Config,TSTransformer\n",
    "import metrics\n",
    "\n",
    "\n",
    "import nonlinear_benchmarks\n",
    "from nonlinear_benchmarks.error_metrics import RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a10f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all random sources to make script fully reproducible\n",
    "torch.manual_seed(452)\n",
    "np.random.seed(55)\n",
    "system_seed = 66 # Controls the system generation\n",
    "data_seed = 0 # Controls the input generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a235fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall settings\n",
    "out_dir_name = \"models\"\n",
    "\n",
    "# System settings\n",
    "nu = 1\n",
    "ny = 1\n",
    "#seq_len = 600\n",
    "batch_size = 320\n",
    "\n",
    "fixed_system = False # Are we testing on a fixed system?\n",
    "\n",
    "# Compute settings\n",
    "no_cuda = False\n",
    "threads = 5\n",
    "compile = False\n",
    "\n",
    "# Configure compute\n",
    "torch.set_num_threads(threads) \n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device_name  =  \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "device_type = 'cpu' # for later use in torch.autocast\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ad2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create out dir\n",
    "out_dir = Path(out_dir_name)\n",
    "exp_data = torch.load(out_dir / \"resume_16k_prbs_40_rep25_last.pt\", map_location=device) # fine-tune on WH systems\n",
    "exp_data2 = torch.load(out_dir / \"resume_16k_CSTR_40_rep25_last.pt\", map_location=device) # fine-tune on CSTR systems\n",
    "exp_data3 = torch.load(out_dir / \"scratch_16k_CSTR_200_rep25_4100.pt\", map_location=device) # scratch on CSTR systems\n",
    "exp_data4 = torch.load(out_dir / \"ckpt_16000_400skip_RNNpatch.pt\", map_location=device) # zero-shot\n",
    "\n",
    "cfg = exp_data[\"cfg\"]\n",
    "# For compatibility with initial experiment without seed\n",
    "try:\n",
    "    cfg.seed\n",
    "except AttributeError:\n",
    "    cfg.seed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94e9c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data[\"iter_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50e8599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.seq_len_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34332c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "model_args = exp_data[\"model_args\"]\n",
    "conf = Config(**model_args)\n",
    "model = TSTransformer(conf).to(device)\n",
    "# model = TSTransformer_paper(conf).to(device)/\n",
    "model.load_state_dict(exp_data[\"model\"]);\n",
    "# cfg.seed +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c653249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "model_args2 = exp_data2[\"model_args\"]\n",
    "conf2 = Config(**model_args2)\n",
    "model2 = TSTransformer(conf2).to(device)\n",
    "# model = TSTransformer_paper(conf).to(device)/\n",
    "model2.load_state_dict(exp_data2[\"model\"]);\n",
    "# cfg.seed +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aafc51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "model_args3 = exp_data3[\"model_args\"]\n",
    "conf3 = Config(**model_args3)\n",
    "model3 = TSTransformer(conf3).to(device)\n",
    "# model = TSTransformer_paper(conf).to(device)/\n",
    "model3.load_state_dict(exp_data3[\"model\"]);\n",
    "# cfg.seed +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38548544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "model_args4 = exp_data4[\"model_args\"]\n",
    "conf4 = Config(**model_args4)\n",
    "model4 = TSTransformer(conf4).to(device)\n",
    "# model = TSTransformer_paper(conf).to(device)/\n",
    "model4.load_state_dict(exp_data4[\"model\"]);\n",
    "# cfg.seed +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff0c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "lin_opts = dict(mag_range=cfg.mag_range, phase_range=cfg.phase_range, strictly_proper=True)\n",
    "# if out_dir_name[-5:] == 'query':\n",
    "# test_ds = WHDataset(nx=cfg.nx, nu=cfg.nu, ny=cfg.ny, \n",
    "#                                         seq_len=cfg.seq_len_ctx+cfg.seq_len_skip+cfg.seq_len_n_in+cfg.seq_len_new,\n",
    "#                         system_seed=cfg.seed, input_seed=cfg.seed+1, noise_seed=cfg.seed+2,\n",
    "#                         **lin_opts)\n",
    "# else:\n",
    "# test_ds = WHDataset(nx=cfg.nx, nu=cfg.nu, ny=cfg.ny, \n",
    "#                                         seq_len=cfg.seq_len_ctx+cfg.seq_len_skip+cfg.seq_len_n_in+cfg.seq_len_new,\n",
    "#                         system_seed=cfg.seed, input_seed=cfg.seed+1, noise_seed=cfg.seed+2,\n",
    "#                         **lin_opts)\n",
    "test_ds = CSTRDataset_numba(seq_len=cfg.seq_len_ctx+cfg.seq_len_skip+cfg.seq_len_n_in+cfg.seq_len_new,\n",
    "                    shift_seed=cfg.seed, input_seed=cfg.seed+1, noise_seed=cfg.seed+2)\n",
    "# test_ds = LinearDynamicalDataset(nx=cfg.nx, nu=cfg.nu, ny=cfg.ny, seq_len=cfg.seq_len_ctx+cfg.seq_len_new)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f80625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([320, 16000, 1])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "batch_y, batch_u= next(iter(test_dl))\n",
    "# print(batch_u.mean(axis = 1),batch_u.std(axis = 1))\n",
    "batch_y = batch_y[:,:,[0]]\n",
    "batch_y = batch_y.to(device)\n",
    "batch_u = batch_u.to(device)\n",
    "# batch_whitenoise = batch_whitenoise.to(device)\n",
    "noise_std = 0.0\n",
    "with torch.no_grad():\n",
    "    batch_y_ctx = batch_y[:, :cfg.seq_len_ctx, :]\n",
    "    batch_u_ctx = batch_u[:, :cfg.seq_len_ctx, :]\n",
    "    batch_y_new = batch_y[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    batch_u_new = batch_u[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    # batch_y_ctx = batch_y_ctx + torch.randn(batch_y_ctx.shape)*noise_std\n",
    "    # print(batch_y_ctx.shape)\n",
    "    batch_y_mean = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    batch_y_std = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    for i in range(len(batch_y_ctx[0,0,:])):\n",
    "        print(i)\n",
    "        print(batch_y_ctx[:,:,i:i+1].shape)\n",
    "        batch_y_mean[:,:,i:i+1], batch_y_std, _, _ = model(batch_y_ctx[:,:,i:i+1], batch_u_ctx, batch_u_new[:,:,:],batch_y_new[:,:,i:i+1],cfg.seq_len_n_in)\n",
    "print(cfg.seq_len_n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dab32ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([320, 16000, 1])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "batch_y, batch_u= next(iter(test_dl))\n",
    "# print(batch_u.mean(axis = 1),batch_u.std(axis = 1))\n",
    "batch_y = batch_y[:,:,[0]]\n",
    "batch_y = batch_y.to(device)\n",
    "batch_u = batch_u.to(device)\n",
    "# batch_whitenoise = batch_whitenoise.to(device)\n",
    "noise_std = 0.0\n",
    "with torch.no_grad():\n",
    "    batch_y_ctx = batch_y[:, :cfg.seq_len_ctx, :]\n",
    "    batch_u_ctx = batch_u[:, :cfg.seq_len_ctx, :]\n",
    "    batch_y_new = batch_y[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    batch_u_new = batch_u[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    # batch_y_ctx = batch_y_ctx + torch.randn(batch_y_ctx.shape)*noise_std\n",
    "    # print(batch_y_ctx.shape)\n",
    "    batch_y_mean2 = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    batch_y_std2 = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    for i in range(len(batch_y_ctx[0,0,:])):\n",
    "        print(i)\n",
    "        print(batch_y_ctx[:,:,i:i+1].shape)\n",
    "        batch_y_mean2[:,:,i:i+1], batch_y_std2, _, _ = model2(batch_y_ctx[:,:,i:i+1], batch_u_ctx, batch_u_new[:,:,:],batch_y_new[:,:,i:i+1],cfg.seq_len_n_in)\n",
    "print(cfg.seq_len_n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f9dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([320, 16000, 1])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "batch_y, batch_u= next(iter(test_dl))\n",
    "# print(batch_u.mean(axis = 1),batch_u.std(axis = 1))\n",
    "batch_y = batch_y[:,:,[0]]\n",
    "batch_y = batch_y.to(device)\n",
    "batch_u = batch_u.to(device)\n",
    "# batch_whitenoise = batch_whitenoise.to(device)\n",
    "noise_std = 0.0\n",
    "with torch.no_grad():\n",
    "    batch_y_ctx = batch_y[:, :cfg.seq_len_ctx, :]\n",
    "    batch_u_ctx = batch_u[:, :cfg.seq_len_ctx, :]\n",
    "    batch_y_new = batch_y[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    batch_u_new = batch_u[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    # batch_y_ctx = batch_y_ctx + torch.randn(batch_y_ctx.shape)*noise_std\n",
    "    # print(batch_y_ctx.shape)\n",
    "    batch_y_mean3 = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    batch_y_std3 = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    for i in range(len(batch_y_ctx[0,0,:])):\n",
    "        print(i)\n",
    "        print(batch_y_ctx[:,:,i:i+1].shape)\n",
    "        batch_y_mean3[:,:,i:i+1], batch_y_std3, _, _ = model3(batch_y_ctx[:,:,i:i+1], batch_u_ctx, batch_u_new[:,:,:],batch_y_new[:,:,i:i+1],cfg.seq_len_n_in)\n",
    "print(cfg.seq_len_n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "589bd31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([320, 16000, 1])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "batch_y, batch_u= next(iter(test_dl))\n",
    "# print(batch_u.mean(axis = 1),batch_u.std(axis = 1))\n",
    "batch_y = batch_y[:,:,[0]]\n",
    "batch_y = batch_y.to(device)\n",
    "batch_u = batch_u.to(device)\n",
    "# batch_whitenoise = batch_whitenoise.to(device)\n",
    "noise_std = 0.0\n",
    "with torch.no_grad():\n",
    "    batch_y_ctx = batch_y[:, :cfg.seq_len_ctx, :]\n",
    "    batch_u_ctx = batch_u[:, :cfg.seq_len_ctx, :]\n",
    "    batch_y_new = batch_y[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    batch_u_new = batch_u[:, cfg.seq_len_ctx+cfg.seq_len_skip:, :]\n",
    "    # batch_y_ctx = batch_y_ctx + torch.randn(batch_y_ctx.shape)*noise_std\n",
    "    # print(batch_y_ctx.shape)\n",
    "    batch_y_mean4 = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    batch_y_std4 = torch.zeros([batch_size,cfg.seq_len_new,len(batch_y_ctx[0,0,:])])\n",
    "    for i in range(len(batch_y_ctx[0,0,:])):\n",
    "        print(i)\n",
    "        print(batch_y_ctx[:,:,i:i+1].shape)\n",
    "        batch_y_mean4[:,:,i:i+1], batch_y_std4, _, _ = model4(batch_y_ctx[:,:,i:i+1], batch_u_ctx, batch_u_new[:,:,:],batch_y_new[:,:,i:i+1],cfg.seq_len_n_in)\n",
    "print(cfg.seq_len_n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6eef187",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_mean = batch_y_mean[:, :, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_std = batch_y_std[:,:, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_mean2 = batch_y_mean2[:, :, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_std2 = batch_y_std2[:,:, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_mean3 = batch_y_mean3[:, :, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_std3 = batch_y_std3[:,:, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_mean4 = batch_y_mean4[:, :, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_std4 = batch_y_std4[:,:, :].to(\"cpu\").detach().numpy()\n",
    "batch_y_new = batch_y_new.to(\"cpu\").detach().numpy()\n",
    "batch_u_new = batch_u_new.to(\"cpu\").detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "083d2180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse over the 16k CSTR, few shot on WH 0.24284391105175018\n"
     ]
    }
   ],
   "source": [
    "skip = 0\n",
    "rmse = metrics.rmse_test(batch_y_new[:, cfg.seq_len_n_in:, 0], batch_y_mean[:,:,0], time_axis=1)\n",
    "print(f\"rmse over the 16k CSTR, few shot on WH {rmse.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bea66a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse over the 16k CSTR, few shot on CSTR 0.11476530134677887\n"
     ]
    }
   ],
   "source": [
    "skip = 0\n",
    "rmse = metrics.rmse_test(batch_y_new[:, cfg.seq_len_n_in:, 0], batch_y_mean2[:,:,0], time_axis=1)\n",
    "print(f\"rmse over the 16k CSTR, few shot on CSTR {rmse.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbdf61a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse over the 16k CSTR, from scratch on CSTR 0.13456487655639648\n"
     ]
    }
   ],
   "source": [
    "skip = 0\n",
    "rmse = metrics.rmse_test(batch_y_new[:, cfg.seq_len_n_in:, 0], batch_y_mean3[:,:,0], time_axis=1)\n",
    "print(f\"rmse over the 16k CSTR, from scratch on CSTR {rmse.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfbecdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse over the 16k CSTR, zeros-hot 1.2493032217025757\n"
     ]
    }
   ],
   "source": [
    "skip = 0\n",
    "rmse = metrics.rmse_test(batch_y_new[:, cfg.seq_len_n_in:, 0], batch_y_mean4[:,:,0], time_axis=1)\n",
    "print(f\"rmse over the 16k CSTR, zeros-hot {rmse.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
